"""Main CLI application."""

from pathlib import Path
from typing import Optional
import typer
from rich.console import Console
from rich.progress import Progress, SpinnerColumn, TextColumn
from rich.table import Table

from ..analyzer import CodebaseAnalyzer
from ..exporters import HTMLExporter, MarkdownExporter, JSONExporter, GraphExporter, ReadmeExporter

app = typer.Typer(
    name="codebase-digest",
    help="AI-native code intelligence engine for semantic codebase analysis",
    no_args_is_help=True
)
console = Console()


@app.command()
def build(
    path: Optional[Path] = typer.Argument(None, help="Path to codebase (default: current directory)"),
    output: Optional[Path] = typer.Option(None, "--output", "-o", help="Output directory (default: .digest)"),
    format: str = typer.Option("all", "--format", "-f", help="Output format: html, markdown, json, or all"),
    graph: bool = typer.Option(False, "--graph", help="Generate interactive call graph visualization"),
    graph_depth: Optional[int] = typer.Option(None, "--graph-depth", help="Limit graph to N hops from entrypoints (default: no limit)")
):
    """Build complete codebase analysis and generate reports."""
    
    # Set defaults
    if path is None:
        path = Path.cwd()
    if output is None:
        output = path / ".digest"
    
    # Validate inputs
    if not path.exists():
        console.print(f"[red]Error: Path {path} does not exist[/red]")
        raise typer.Exit(1)
    
    if not path.is_dir():
        console.print(f"[red]Error: Path {path} is not a directory[/red]")
        raise typer.Exit(1)
    
    # Create output directory
    output.mkdir(exist_ok=True)
    
    console.print(f"[blue]Analyzing codebase at:[/blue] {path}")
    console.print(f"[blue]Output directory:[/blue] {output}")
    
    # Analyze codebase
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        console=console
    ) as progress:
        
        task = progress.add_task("Analyzing codebase...", total=None)
        analyzer = CodebaseAnalyzer(path)
        analysis = analyzer.analyze()
        progress.update(task, description="Analysis complete!")
    
    # Generate reports
    formats_to_generate = []
    if format == "all":
        formats_to_generate = ["html", "markdown", "json"]
    else:
        formats_to_generate = [format]
    
    for fmt in formats_to_generate:
        if fmt == "html":
            html_exporter = HTMLExporter(analysis)
            html_exporter.export(output / "report.html")
            console.print(f"[green]✓[/green] Generated HTML report: {output / 'report.html'}")
        
        elif fmt == "markdown":
            md_exporter = MarkdownExporter(analysis)
            md_exporter.export(output / "architecture.md")
            console.print(f"[green]✓[/green] Generated Markdown report: {output / 'architecture.md'}")
        
        elif fmt == "json":
            json_exporter = JSONExporter(analysis)
            json_exporter.export(output / "entities.json")
            console.print(f"[green]✓[/green] Generated JSON data: {output / 'entities.json'}")
        
        else:
            console.print(f"[red]Error: Unknown format '{fmt}'[/red]")
            raise typer.Exit(1)
    
    # Generate additional files
    _generate_flows_md(analysis, output / "flows.md")
    _generate_ai_context_md(analysis, output / "ai-context.md")
    
    # Generate project README.md
    readme_exporter = ReadmeExporter(analysis)
    readme_exporter.export(output / "README.md")
    console.print(f"[green]✓[/green] Generated project README: {output / 'README.md'}")
    
    # Always generate interactive call graph
    try:
        graph_exporter = GraphExporter(analysis, max_depth=graph_depth)
        graph_exporter.export(output / "callgraph.html")
        console.print(f"[green]✓[/green] Generated interactive call graph: {output / 'callgraph.html'}")
        
        # Show graph statistics
        stats = graph_exporter.get_graph_stats()
        console.print(f"[blue]Graph Stats:[/blue] {stats['nodes']} nodes, {stats['edges']} edges, {stats['components']} components")
        
    except ImportError:
        console.print(f"[red]Error: pyvis not installed. Install with: pip install pyvis[/red]")
    except Exception as e:
        console.print(f"[red]Error generating call graph: {e}[/red]")
    
    # Generate additional call graph if explicitly requested (for backward compatibility)
    if graph:
        console.print("[blue]Note: Call graph is now generated by default[/blue]")
    
    total_files = len(formats_to_generate) + 4  # +4 for flows.md, ai-context.md, README.md, callgraph.html
    console.print(f"\n[green]Analysis complete![/green] Generated {total_files} files in {output}")


@app.command()
def stats(
    path: Optional[Path] = typer.Argument(None, help="Path to codebase (default: current directory)")
):
    """Show quick statistics about the codebase."""
    
    if path is None:
        path = Path.cwd()
    
    if not path.exists() or not path.is_dir():
        console.print(f"[red]Error: Invalid directory {path}[/red]")
        raise typer.Exit(1)
    
    console.print(f"[blue]Analyzing:[/blue] {path}")
    
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        console=console
    ) as progress:
        
        task = progress.add_task("Gathering statistics...", total=None)
        analyzer = CodebaseAnalyzer(path)
        analysis = analyzer.analyze()
        progress.update(task, description="Complete!")
    
    # Create statistics table
    table = Table(title=f"Codebase Statistics - {path.name}")
    table.add_column("Metric", style="cyan")
    table.add_column("Value", style="green")
    
    table.add_row("Total Files", str(analysis.total_files))
    table.add_row("Lines of Code", f"{analysis.total_lines:,}")
    table.add_row("Languages", ", ".join(sorted(analysis.languages)))
    table.add_row("Functions", str(len([s for s in analysis.symbols if s.type == 'function'])))
    table.add_row("Classes", str(len([s for s in analysis.symbols if s.type == 'class'])))
    table.add_row("Domain Entities", str(len(analysis.domain_entities)))
    table.add_row("Execution Flows", str(len(analysis.execution_flows)))
    table.add_row("Complexity Score", f"{analysis.complexity_score:.1f}")
    
    console.print(table)


@app.command()
def query(
    search_term: str = typer.Argument(..., help="Search term or pattern"),
    path: Optional[Path] = typer.Argument(None, help="Path to codebase (default: current directory)")
):
    """Search for patterns in the codebase analysis."""
    
    if path is None:
        path = Path.cwd()
    
    if not path.exists() or not path.is_dir():
        console.print(f"[red]Error: Invalid directory {path}[/red]")
        raise typer.Exit(1)
    
    console.print(f"[blue]Searching for:[/blue] '{search_term}' in {path}")
    
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        console=console
    ) as progress:
        
        task = progress.add_task("Analyzing and searching...", total=None)
        analyzer = CodebaseAnalyzer(path)
        analysis = analyzer.analyze()
        progress.update(task, description="Searching...")
        
        results = _search_analysis(analysis, search_term.lower())
        progress.update(task, description="Complete!")
    
    if not results:
        console.print(f"[yellow]No results found for '{search_term}'[/yellow]")
        return
    
    console.print(f"\n[green]Found {len(results)} results:[/green]")
    
    for result in results:
        console.print(f"[cyan]•[/cyan] {result}")


def _generate_flows_md(analysis, output_path: Path):
    """Generate flows.md file."""
    content = "# Execution Flows\n\n"
    
    if not analysis.execution_flows:
        content += "No execution flows detected.\n"
    else:
        for flow in analysis.execution_flows:
            content += f"## {flow.name}\n\n"
            content += f"{flow.description}\n\n"
            content += f"**Entry Point:** `{flow.entry_point}`\n\n"
            content += "**Flow Steps:**\n"
            for i, step in enumerate(flow.steps, 1):
                content += f"{i}. `{step}`\n"
            content += "\n"
            
            if flow.files_involved:
                content += "**Files Involved:**\n"
                for file_path in sorted(flow.files_involved):
                    rel_path = file_path.relative_to(analysis.root_path) if file_path.is_absolute() else file_path
                    content += f"- {rel_path}\n"
                content += "\n"
    
    output_path.write_text(content, encoding='utf-8')


def _generate_ai_context_md(analysis, output_path: Path):
    """Generate AI-optimized context file."""
    content = f"""# AI Context - {analysis.root_path.name}

## System Overview
This codebase contains {analysis.total_files} files with {analysis.total_lines:,} lines of code across {len(analysis.languages)} languages.

## Key Components
"""
    
    # Add top symbols
    for symbol in analysis.symbols[:20]:
        rel_path = symbol.file_path.relative_to(analysis.root_path)
        content += f"- `{symbol.name}` ({symbol.type}) - {rel_path}:{symbol.line_number}\n"
    
    content += "\n## Domain Entities\n"
    for entity in analysis.domain_entities:
        rel_path = entity.file_path.relative_to(analysis.root_path)
        content += f"- `{entity.name}` - {rel_path}\n"
    
    content += "\n## Execution Flows\n"
    for flow in analysis.execution_flows:
        content += f"- {flow.name}: {' → '.join(flow.steps[:3])}{'...' if len(flow.steps) > 3 else ''}\n"
    
    output_path.write_text(content, encoding='utf-8')


def _search_analysis(analysis, search_term: str):
    """Search through analysis results."""
    results = []
    
    # Search symbols
    for symbol in analysis.symbols:
        if search_term in symbol.name.lower():
            rel_path = symbol.file_path.relative_to(analysis.root_path)
            results.append(f"Symbol: {symbol.name} ({symbol.type}) in {rel_path}:{symbol.line_number}")
    
    # Search domain entities
    for entity in analysis.domain_entities:
        if search_term in entity.name.lower():
            rel_path = entity.file_path.relative_to(analysis.root_path)
            results.append(f"Entity: {entity.name} in {rel_path}")
    
    # Search execution flows
    for flow in analysis.execution_flows:
        if search_term in flow.name.lower() or any(search_term in step.lower() for step in flow.steps):
            results.append(f"Flow: {flow.name} - {flow.description}")
    
    return results


if __name__ == "__main__":
    app()